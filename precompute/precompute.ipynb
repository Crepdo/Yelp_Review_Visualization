{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get average star of a shop in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  3217\n",
      "2008 3 2022 1 167\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funny</th>\n",
       "      <th>useful</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68797</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>nzmIa6HDRK43HHq2zoDu2Q</td>\n",
       "      <td>Martinis and lobster... now that's the good li...</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2008-03-13 03:03:33</td>\n",
       "      <td>o-t-i7nbT5N_cmkCXs5oDQ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77460</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HJbIab9q-e42ATXVPdhB8A</td>\n",
       "      <td>We ordered the parmesan / butter oysters, alon...</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2008-04-13 22:18:34</td>\n",
       "      <td>b9Azt2DNyTP9QJZdRFs8jw</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60691</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Wu7ihrc1bUerjr2vTr5nIw</td>\n",
       "      <td>Drago's is a Croatian family-owned restaurant ...</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2008-06-08 14:13:02</td>\n",
       "      <td>MJqwVw8SyIuSdfqrg07QzA</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58400</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>WdweC3kAy1HX9_KeE8W0Tg</td>\n",
       "      <td>ahhhhhh....c'mon gustav....leave nola alone......</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2008-09-01 01:50:41</td>\n",
       "      <td>SxBi6fjWUCyIeDZd8jSvmQ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69885</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48G80J0JMp6nrOVaLn3eKA</td>\n",
       "      <td>Dear Home,\\n\\nI had BIG, MEATY oysters at this...</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2008-09-24 18:21:41</td>\n",
       "      <td>OF1Dwu3fWeyNzX2ehlyM3A</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89297</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>rKDuMoQ7ohc6dW0fTkJkDg</td>\n",
       "      <td>I was told about Drago's from a friend who rec...</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-01-05 03:27:35</td>\n",
       "      <td>v24RjY1EMIqUXXoFbeYZXA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91071</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-e7U_NiNLBIvURoG4xEcUA</td>\n",
       "      <td>We had reservations via Open Table and it took...</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-01-07 15:33:36</td>\n",
       "      <td>1nMmVZocQ0j_8O4MAtTgOg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88949</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>z-Qp8w0JYQnQ4badseCsdg</td>\n",
       "      <td>We came here for my moms 70th bday. First our ...</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2022-01-10 02:27:17</td>\n",
       "      <td>kV3mDYRNoB3KO8TBo7vEqw</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90821</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>qxtn09m-eqymJh6KilEPtw</td>\n",
       "      <td>I was hesitant because I am not one for oyster...</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022-01-15 21:30:52</td>\n",
       "      <td>VH8f-I1_ka7NWJjZambcPQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89197</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>fWhc3qtm0SeVP0nHLHhtSA</td>\n",
       "      <td>Upon booking our stay at the Hilton Riverside ...</td>\n",
       "      <td>DcBLYSvOuWcNReolRVr12A</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2022-01-16 00:31:44</td>\n",
       "      <td>0tQxBAoXvJmFXf5DmDcn6Q</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3217 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       funny  useful               review_id  \\\n",
       "68797      0       3  nzmIa6HDRK43HHq2zoDu2Q   \n",
       "77460      0       0  HJbIab9q-e42ATXVPdhB8A   \n",
       "60691      1       2  Wu7ihrc1bUerjr2vTr5nIw   \n",
       "58400      0       0  WdweC3kAy1HX9_KeE8W0Tg   \n",
       "69885      0       1  48G80J0JMp6nrOVaLn3eKA   \n",
       "...      ...     ...                     ...   \n",
       "89297      0       0  rKDuMoQ7ohc6dW0fTkJkDg   \n",
       "91071      0       0  -e7U_NiNLBIvURoG4xEcUA   \n",
       "88949      0       0  z-Qp8w0JYQnQ4badseCsdg   \n",
       "90821      0       0  qxtn09m-eqymJh6KilEPtw   \n",
       "89197      0       0  fWhc3qtm0SeVP0nHLHhtSA   \n",
       "\n",
       "                                                    text  \\\n",
       "68797  Martinis and lobster... now that's the good li...   \n",
       "77460  We ordered the parmesan / butter oysters, alon...   \n",
       "60691  Drago's is a Croatian family-owned restaurant ...   \n",
       "58400  ahhhhhh....c'mon gustav....leave nola alone......   \n",
       "69885  Dear Home,\\n\\nI had BIG, MEATY oysters at this...   \n",
       "...                                                  ...   \n",
       "89297  I was told about Drago's from a friend who rec...   \n",
       "91071  We had reservations via Open Table and it took...   \n",
       "88949  We came here for my moms 70th bday. First our ...   \n",
       "90821  I was hesitant because I am not one for oyster...   \n",
       "89197  Upon booking our stay at the Hilton Riverside ...   \n",
       "\n",
       "                  business_id  stars                 date  \\\n",
       "68797  DcBLYSvOuWcNReolRVr12A    4.0  2008-03-13 03:03:33   \n",
       "77460  DcBLYSvOuWcNReolRVr12A    4.0  2008-04-13 22:18:34   \n",
       "60691  DcBLYSvOuWcNReolRVr12A    4.0  2008-06-08 14:13:02   \n",
       "58400  DcBLYSvOuWcNReolRVr12A    4.0  2008-09-01 01:50:41   \n",
       "69885  DcBLYSvOuWcNReolRVr12A    5.0  2008-09-24 18:21:41   \n",
       "...                       ...    ...                  ...   \n",
       "89297  DcBLYSvOuWcNReolRVr12A    4.0  2022-01-05 03:27:35   \n",
       "91071  DcBLYSvOuWcNReolRVr12A    5.0  2022-01-07 15:33:36   \n",
       "88949  DcBLYSvOuWcNReolRVr12A    3.0  2022-01-10 02:27:17   \n",
       "90821  DcBLYSvOuWcNReolRVr12A    4.0  2022-01-15 21:30:52   \n",
       "89197  DcBLYSvOuWcNReolRVr12A    5.0  2022-01-16 00:31:44   \n",
       "\n",
       "                      user_id  cool  \n",
       "68797  o-t-i7nbT5N_cmkCXs5oDQ     3  \n",
       "77460  b9Azt2DNyTP9QJZdRFs8jw     1  \n",
       "60691  MJqwVw8SyIuSdfqrg07QzA     2  \n",
       "58400  SxBi6fjWUCyIeDZd8jSvmQ     1  \n",
       "69885  OF1Dwu3fWeyNzX2ehlyM3A     0  \n",
       "...                       ...   ...  \n",
       "89297  v24RjY1EMIqUXXoFbeYZXA     0  \n",
       "91071  1nMmVZocQ0j_8O4MAtTgOg     0  \n",
       "88949  kV3mDYRNoB3KO8TBo7vEqw     0  \n",
       "90821  VH8f-I1_ka7NWJjZambcPQ     0  \n",
       "89197  0tQxBAoXvJmFXf5DmDcn6Q     0  \n",
       "\n",
       "[3217 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Get star of a shop in each month\n",
    ":param business_id: The shop's id\n",
    ":returns: Star of the shop every month as a list, the start month and the end month\n",
    "'''\n",
    "# DcBLYSvOuWcNReolRVr12A Drago's\n",
    "business_id = 'DcBLYSvOuWcNReolRVr12A'\n",
    "df = pd.read_csv(\"./new_orlean_restaurant_reviews.csv\")\n",
    "target_bus_df = df.loc[df['business_id'] == business_id]\n",
    "print(\"number of reviews: \",len(target_bus_df.index))\n",
    "target_bus_df = target_bus_df.sort_values(by=['date'])\n",
    "\n",
    "start_year = int(target_bus_df.iloc[0].at['date'][0:4])\n",
    "end_year = int(target_bus_df.iloc[-1].at['date'][0:4])\n",
    "start_month = int(target_bus_df.iloc[0].at['date'][5:7])\n",
    "end_month = int(target_bus_df.iloc[-1].at['date'][5:7])\n",
    "# star - month dictionary re-scaled to 0 - (month_count-1)\n",
    "star_month_dict = {}\n",
    "for i in range(0,len(target_bus_df.index)):\n",
    "    real_year = int(target_bus_df.iloc[i].at['date'][0:4])\n",
    "    real_month = int(target_bus_df.iloc[i].at['date'][5:7])\n",
    "    key_month = (real_year - start_year) * 12 + (real_month - start_month)\n",
    "    if key_month in star_month_dict:\n",
    "        star_month_dict[key_month].append(target_bus_df.iloc[i].at['stars'])\n",
    "    else:\n",
    "        star_month_dict[key_month] = [target_bus_df.iloc[i].at['stars']]\n",
    "# print(star_month_dict)\n",
    "# ensure every month has a average star\n",
    "month_count = (end_year - start_year) * 12 + (end_month - start_month) + 1\n",
    "per_month_stars = []\n",
    "for key_month in range(month_count):\n",
    "    if key_month in star_month_dict:\n",
    "        per_month_stars.append(sum(star_month_dict[key_month])/len(star_month_dict[key_month]))\n",
    "    else:\n",
    "        per_month_stars.append(per_month_stars[key_month-1])\n",
    "\n",
    "# print (per_month_stars, start_year, start_month, end_year, end_month)\n",
    "print (start_year, start_month, end_year, end_month, month_count)\n",
    "target_bus_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modelling of the shop's review in each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from pprint import pprint# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "# spaCy for preprocessing\n",
    "import spacy\n",
    "# import pyLDAvis.gensim\n",
    "import gensim\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare stopwords  \n",
    "We may visualize the cleaned corpus using wordcloud  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "( run this only when the first time you use it )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cpdo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normal case just run below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','great'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  3217\n",
      "2008 3 2022 1 167\n"
     ]
    }
   ],
   "source": [
    "# DcBLYSvOuWcNReolRVr12A Drago's\n",
    "business_id = 'DcBLYSvOuWcNReolRVr12A'\n",
    "df = pd.read_csv(\"./new_orlean_restaurant_reviews.csv\")\n",
    "target_bus_df = df.loc[df['business_id'] == business_id]\n",
    "print(\"number of reviews: \",len(target_bus_df.index))\n",
    "target_bus_df = target_bus_df.sort_values(by=['date'])\n",
    "\n",
    "start_year = int(target_bus_df.iloc[0].at['date'][0:4])\n",
    "end_year = int(target_bus_df.iloc[-1].at['date'][0:4])\n",
    "start_month = int(target_bus_df.iloc[0].at['date'][5:7])\n",
    "end_month = int(target_bus_df.iloc[-1].at['date'][5:7])\n",
    "# text - month dictionary re-scaled to 0 - (month_count-1)\n",
    "text_month_dict = {}\n",
    "for i in range(0,len(target_bus_df.index)):\n",
    "    real_year = int(target_bus_df.iloc[i].at['date'][0:4])\n",
    "    real_month = int(target_bus_df.iloc[i].at['date'][5:7])\n",
    "    key_month = (real_year - start_year) * 12 + (real_month - start_month)\n",
    "    if key_month in text_month_dict:\n",
    "        text_month_dict[key_month].append(target_bus_df.iloc[i].at['text'])\n",
    "    else:\n",
    "        text_month_dict[key_month] = [target_bus_df.iloc[i].at['text']]\n",
    "        \n",
    "# ensure every month has a average star\n",
    "month_count = (end_year - start_year) * 12 + (end_month - start_month) + 1\n",
    "per_month_texts = []\n",
    "for key_month in range(month_count):\n",
    "    if key_month in text_month_dict:\n",
    "        per_month_texts.append(text_month_dict[key_month])\n",
    "    else:\n",
    "        per_month_texts.append(per_month_texts[key_month-1]) \n",
    "# print (per_month_stars, start_year, start_month, end_year, end_month)\n",
    "print (start_year, start_month, end_year, end_month, month_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's just choose a month with >=8 reviews as a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test text is the month: 166 th\n"
     ]
    }
   ],
   "source": [
    "test_text = \"\"\n",
    "for key_month in range(month_count):\n",
    "    if len(per_month_texts[key_month]) >= 8:\n",
    "        test_text = per_month_texts[key_month]\n",
    "print(\"the test text is the month:\",key_month,\"th\")\n",
    "# test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some additional cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Delicious food and excellent service! Ate from the small plates menu and all hit the mark. The charbroiled oysters melt in your mouth! Followed by the crawfish mac and cheese and gator tacos!',\n",
       " 'We vacationed in NOLA for a week.. Came here for dinner. Had reservations and waited 15 minutes which wasn t horrible given dinner rush hours. After having chargrilled oysters at other nearby restaurants I feel they are all the same as other places here, all good and tasty. But the star were the fried shrimp and fish platter. The shrimp was so good! Lightly breaded, huge and Juicy and lots of flavor. The raw oysters were really fresh and sweet. Our waiter was very attentive and kind. Would definitely come back for the fried shrimp!',\n",
       " 'Daaaaang, my mom hyped this place up for a reason! She has been to NOLA many times, and this was my 1st visit. She made sure I tried the best oysters in the city, and I was honestly not feeling it. I m not big into seafood, BUT.... these blew me away! The charbroil on them is freakin  delicious with the butter and bread to clean it all up with. Our friends got the crawfish mac n cheese and let me try some, which was also out of this world! Can t wait to go back here again someday! If you haven t tried charbroiled oysters, just do it! You won t be disappointed.  Also, their bread pudding is to die for. Super moist like how it should be and not all dried out.',\n",
       " 'Quick seating, great service and the chargrilled oysters are fantastic. As a main entree I had the seafood pasta which was good. Plenty of seafood in it. My daughter had the shrimp and grits which she wasn t crazy about but it was decent, my husband had the catfish platter which was really good. Overall would return, especially for those oysters. Oh and you ve gotta make sure you have your vaccine card in hand to be seated.',\n",
       " 'Sorry. The raw oyster are excellent. The charbroiled oysters are over breaded. The main dishes are disguised with too much hot sauce. The drinks are weak. Our waiter was excellent but he could not make up for the misses in the menus. I would not go here again.',\n",
       " 'I was told about Drago s from a friend who recently visited New Orleans. It is located in the Hilton hotel. We went on a Saturday night and was a little worried because they don t take reservations. However, we didn t have a wait time and were seated right away.   I ordered the gumbo, charbroiled oysters, and baked market fish. The highlight would have to be the oysters. They were pretty cheap and absolutely delicious. They were so flavorful and you just have to try them. The gumbo was also pretty good and tasted much better than the gumbo I ordered on bourbon street. The fish was good but not worth the price. Stop by and try the oysters.   We also ordered drinks but they were nothing spectacular.',\n",
       " 'We had reservations via Open Table and it took a little bit to get seated but it wasn t too long of a wait. This place was delicious!!! The fried shrimp were huge and juicy, and most importantly the breading was so light yet the shrimp were crispy. Some places the breading is super thick and takes away from the taste. My first time trying grilled oysters and I loved them!! My friends had the raw oysters and enjoyed those as well. Our server was great - very pleasant with conversation and his service was excellent. And he was properly masked!  Only improvement would to have a bigger table to fit all of our food. =  We will definitely return here next time we re in Nola!',\n",
       " 'We came here for my moms 70th bday. First our waitress Brittney was great!! We orders the alligator bites for appetizer since neither had them, to chicken to try the charbroiled oysters which by the way we tried elsewhere . It wasn t even suggested to try even thought that is one of y all popular menu item. Alligator bites were great as long as they were hot. We ordered the fried catfish and shrimp combo with fries an onion rings and the sirloin medium  with lobster and mashed potatoes and side Cesar salad. The fried platter was ok, fries seemed dbl fried, and the onions rings 2  were to hard. The sirloin was cooked well done and the lobster was to tough to eat. We asked for that plate to be replace with the fried platter, which actually came out piping hot, better than mine. Dessert was brownie with ice cream and a LOAD of whipped cream, which was almost the best thing about this birthday dinner besides the cesar salad. For the price it def could of been better. May come back and try the oysters only.',\n",
       " 'I was hesitant because I am not one for oysters  and I work at an oyster bar back home  but holy crap, so yummy!!! We were all very impressed with our food. The only complaint is we had a girl in our party who doesn t eat seafood and online showed a much larger menu and we were told we weren t allowed to order certain things, so she couldn t even get chicken tenders. So make sure everyone loves seafood or doesn t have an allergy!',\n",
       " 'Upon booking our stay at the Hilton Riverside my fiancé and I learned this restaurant was on property. Upon looking at some of the reviews we decided against planning to come here for a meal. Wellll the reviews are wrong. On this rainy Saturday afternoon, our last full day in Nola, we decided not to leave the hotel for lunch and instead dine at Drago s. This was the best decision!! The service here was incredible. Our server Ashanti was such a sweetheart making sure our drinks were never empty, checking on us about our food and just being a little sunshine on this cloudy day!   To start we had the chargrilled oysters, cuz after all its what they re famous for! They were outrageous. The flavors on them and the size of them makes them a definite must have when coming here. For our meals I had the seafood gumbo bowl. The flavors in this dish are just perfect!! Definitely recommend dipping some bread in there!!! My fiancé had the seafood pasta which was sooo deliciously creamy!  Overall I would definitely check this place out if you re in Nola. They are a great place with great staff and great food!!!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove ()\n",
    "test_text = [sent.replace(\"(\",\" \") for sent in test_text]\n",
    "test_text = [sent.replace(\")\",\" \")  for sent in test_text]    \n",
    "# Remove new line characters \n",
    "test_text = [sent.replace(\"\\n\",\" \") for sent in test_text]  \n",
    "# Remove distracting single quotes \n",
    "test_text = [sent.replace(\"\\'\",\" \") for sent in test_text]  \n",
    "test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove punctuations and tokenize words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['delicious',\n",
       "  'food',\n",
       "  'and',\n",
       "  'excellent',\n",
       "  'service',\n",
       "  'ate',\n",
       "  'from',\n",
       "  'the',\n",
       "  'small',\n",
       "  'plates',\n",
       "  'menu',\n",
       "  'and',\n",
       "  'all',\n",
       "  'hit',\n",
       "  'the',\n",
       "  'mark',\n",
       "  'the',\n",
       "  'charbroiled',\n",
       "  'oysters',\n",
       "  'melt',\n",
       "  'in',\n",
       "  'your',\n",
       "  'mouth',\n",
       "  'followed',\n",
       "  'by',\n",
       "  'the',\n",
       "  'crawfish',\n",
       "  'mac',\n",
       "  'and',\n",
       "  'cheese',\n",
       "  'and',\n",
       "  'gator',\n",
       "  'tacos'],\n",
       " ['we',\n",
       "  'vacationed',\n",
       "  'in',\n",
       "  'nola',\n",
       "  'for',\n",
       "  'week',\n",
       "  'came',\n",
       "  'here',\n",
       "  'for',\n",
       "  'dinner',\n",
       "  'had',\n",
       "  'reservations',\n",
       "  'and',\n",
       "  'waited',\n",
       "  'minutes',\n",
       "  'which',\n",
       "  'wasn',\n",
       "  'horrible',\n",
       "  'given',\n",
       "  'dinner',\n",
       "  'rush',\n",
       "  'hours',\n",
       "  'after',\n",
       "  'having',\n",
       "  'chargrilled',\n",
       "  'oysters',\n",
       "  'at',\n",
       "  'other',\n",
       "  'nearby',\n",
       "  'restaurants',\n",
       "  'feel',\n",
       "  'they',\n",
       "  'are',\n",
       "  'all',\n",
       "  'the',\n",
       "  'same',\n",
       "  'as',\n",
       "  'other',\n",
       "  'places',\n",
       "  'here',\n",
       "  'all',\n",
       "  'good',\n",
       "  'and',\n",
       "  'tasty',\n",
       "  'but',\n",
       "  'the',\n",
       "  'star',\n",
       "  'were',\n",
       "  'the',\n",
       "  'fried',\n",
       "  'shrimp',\n",
       "  'and',\n",
       "  'fish',\n",
       "  'platter',\n",
       "  'the',\n",
       "  'shrimp',\n",
       "  'was',\n",
       "  'so',\n",
       "  'good',\n",
       "  'lightly',\n",
       "  'breaded',\n",
       "  'huge',\n",
       "  'and',\n",
       "  'juicy',\n",
       "  'and',\n",
       "  'lots',\n",
       "  'of',\n",
       "  'flavor',\n",
       "  'the',\n",
       "  'raw',\n",
       "  'oysters',\n",
       "  'were',\n",
       "  'really',\n",
       "  'fresh',\n",
       "  'and',\n",
       "  'sweet',\n",
       "  'our',\n",
       "  'waiter',\n",
       "  'was',\n",
       "  'very',\n",
       "  'attentive',\n",
       "  'and',\n",
       "  'kind',\n",
       "  'would',\n",
       "  'definitely',\n",
       "  'come',\n",
       "  'back',\n",
       "  'for',\n",
       "  'the',\n",
       "  'fried',\n",
       "  'shrimp'],\n",
       " ['daaaaang',\n",
       "  'my',\n",
       "  'mom',\n",
       "  'hyped',\n",
       "  'this',\n",
       "  'place',\n",
       "  'up',\n",
       "  'for',\n",
       "  'reason',\n",
       "  'she',\n",
       "  'has',\n",
       "  'been',\n",
       "  'to',\n",
       "  'nola',\n",
       "  'many',\n",
       "  'times',\n",
       "  'and',\n",
       "  'this',\n",
       "  'was',\n",
       "  'my',\n",
       "  'st',\n",
       "  'visit',\n",
       "  'she',\n",
       "  'made',\n",
       "  'sure',\n",
       "  'tried',\n",
       "  'the',\n",
       "  'best',\n",
       "  'oysters',\n",
       "  'in',\n",
       "  'the',\n",
       "  'city',\n",
       "  'and',\n",
       "  'was',\n",
       "  'honestly',\n",
       "  'not',\n",
       "  'feeling',\n",
       "  'it',\n",
       "  'not',\n",
       "  'big',\n",
       "  'into',\n",
       "  'seafood',\n",
       "  'but',\n",
       "  'these',\n",
       "  'blew',\n",
       "  'me',\n",
       "  'away',\n",
       "  'the',\n",
       "  'charbroil',\n",
       "  'on',\n",
       "  'them',\n",
       "  'is',\n",
       "  'freakin',\n",
       "  'delicious',\n",
       "  'with',\n",
       "  'the',\n",
       "  'butter',\n",
       "  'and',\n",
       "  'bread',\n",
       "  'to',\n",
       "  'clean',\n",
       "  'it',\n",
       "  'all',\n",
       "  'up',\n",
       "  'with',\n",
       "  'our',\n",
       "  'friends',\n",
       "  'got',\n",
       "  'the',\n",
       "  'crawfish',\n",
       "  'mac',\n",
       "  'cheese',\n",
       "  'and',\n",
       "  'let',\n",
       "  'me',\n",
       "  'try',\n",
       "  'some',\n",
       "  'which',\n",
       "  'was',\n",
       "  'also',\n",
       "  'out',\n",
       "  'of',\n",
       "  'this',\n",
       "  'world',\n",
       "  'can',\n",
       "  'wait',\n",
       "  'to',\n",
       "  'go',\n",
       "  'back',\n",
       "  'here',\n",
       "  'again',\n",
       "  'someday',\n",
       "  'if',\n",
       "  'you',\n",
       "  'haven',\n",
       "  'tried',\n",
       "  'charbroiled',\n",
       "  'oysters',\n",
       "  'just',\n",
       "  'do',\n",
       "  'it',\n",
       "  'you',\n",
       "  'won',\n",
       "  'be',\n",
       "  'disappointed',\n",
       "  'also',\n",
       "  'their',\n",
       "  'bread',\n",
       "  'pudding',\n",
       "  'is',\n",
       "  'to',\n",
       "  'die',\n",
       "  'for',\n",
       "  'super',\n",
       "  'moist',\n",
       "  'like',\n",
       "  'how',\n",
       "  'it',\n",
       "  'should',\n",
       "  'be',\n",
       "  'and',\n",
       "  'not',\n",
       "  'all',\n",
       "  'dried',\n",
       "  'out'],\n",
       " ['quick',\n",
       "  'seating',\n",
       "  'great',\n",
       "  'service',\n",
       "  'and',\n",
       "  'the',\n",
       "  'chargrilled',\n",
       "  'oysters',\n",
       "  'are',\n",
       "  'fantastic',\n",
       "  'as',\n",
       "  'main',\n",
       "  'entree',\n",
       "  'had',\n",
       "  'the',\n",
       "  'seafood',\n",
       "  'pasta',\n",
       "  'which',\n",
       "  'was',\n",
       "  'good',\n",
       "  'plenty',\n",
       "  'of',\n",
       "  'seafood',\n",
       "  'in',\n",
       "  'it',\n",
       "  'my',\n",
       "  'daughter',\n",
       "  'had',\n",
       "  'the',\n",
       "  'shrimp',\n",
       "  'and',\n",
       "  'grits',\n",
       "  'which',\n",
       "  'she',\n",
       "  'wasn',\n",
       "  'crazy',\n",
       "  'about',\n",
       "  'but',\n",
       "  'it',\n",
       "  'was',\n",
       "  'decent',\n",
       "  'my',\n",
       "  'husband',\n",
       "  'had',\n",
       "  'the',\n",
       "  'catfish',\n",
       "  'platter',\n",
       "  'which',\n",
       "  'was',\n",
       "  'really',\n",
       "  'good',\n",
       "  'overall',\n",
       "  'would',\n",
       "  'return',\n",
       "  'especially',\n",
       "  'for',\n",
       "  'those',\n",
       "  'oysters',\n",
       "  'oh',\n",
       "  'and',\n",
       "  'you',\n",
       "  've',\n",
       "  'gotta',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'you',\n",
       "  'have',\n",
       "  'your',\n",
       "  'vaccine',\n",
       "  'card',\n",
       "  'in',\n",
       "  'hand',\n",
       "  'to',\n",
       "  'be',\n",
       "  'seated'],\n",
       " ['sorry',\n",
       "  'the',\n",
       "  'raw',\n",
       "  'oyster',\n",
       "  'are',\n",
       "  'excellent',\n",
       "  'the',\n",
       "  'charbroiled',\n",
       "  'oysters',\n",
       "  'are',\n",
       "  'over',\n",
       "  'breaded',\n",
       "  'the',\n",
       "  'main',\n",
       "  'dishes',\n",
       "  'are',\n",
       "  'disguised',\n",
       "  'with',\n",
       "  'too',\n",
       "  'much',\n",
       "  'hot',\n",
       "  'sauce',\n",
       "  'the',\n",
       "  'drinks',\n",
       "  'are',\n",
       "  'weak',\n",
       "  'our',\n",
       "  'waiter',\n",
       "  'was',\n",
       "  'excellent',\n",
       "  'but',\n",
       "  'he',\n",
       "  'could',\n",
       "  'not',\n",
       "  'make',\n",
       "  'up',\n",
       "  'for',\n",
       "  'the',\n",
       "  'misses',\n",
       "  'in',\n",
       "  'the',\n",
       "  'menus',\n",
       "  'would',\n",
       "  'not',\n",
       "  'go',\n",
       "  'here',\n",
       "  'again'],\n",
       " ['was',\n",
       "  'told',\n",
       "  'about',\n",
       "  'drago',\n",
       "  'from',\n",
       "  'friend',\n",
       "  'who',\n",
       "  'recently',\n",
       "  'visited',\n",
       "  'new',\n",
       "  'orleans',\n",
       "  'it',\n",
       "  'is',\n",
       "  'located',\n",
       "  'in',\n",
       "  'the',\n",
       "  'hilton',\n",
       "  'hotel',\n",
       "  'we',\n",
       "  'went',\n",
       "  'on',\n",
       "  'saturday',\n",
       "  'night',\n",
       "  'and',\n",
       "  'was',\n",
       "  'little',\n",
       "  'worried',\n",
       "  'because',\n",
       "  'they',\n",
       "  'don',\n",
       "  'take',\n",
       "  'reservations',\n",
       "  'however',\n",
       "  'we',\n",
       "  'didn',\n",
       "  'have',\n",
       "  'wait',\n",
       "  'time',\n",
       "  'and',\n",
       "  'were',\n",
       "  'seated',\n",
       "  'right',\n",
       "  'away',\n",
       "  'ordered',\n",
       "  'the',\n",
       "  'gumbo',\n",
       "  'charbroiled',\n",
       "  'oysters',\n",
       "  'and',\n",
       "  'baked',\n",
       "  'market',\n",
       "  'fish',\n",
       "  'the',\n",
       "  'highlight',\n",
       "  'would',\n",
       "  'have',\n",
       "  'to',\n",
       "  'be',\n",
       "  'the',\n",
       "  'oysters',\n",
       "  'they',\n",
       "  'were',\n",
       "  'pretty',\n",
       "  'cheap',\n",
       "  'and',\n",
       "  'absolutely',\n",
       "  'delicious',\n",
       "  'they',\n",
       "  'were',\n",
       "  'so',\n",
       "  'flavorful',\n",
       "  'and',\n",
       "  'you',\n",
       "  'just',\n",
       "  'have',\n",
       "  'to',\n",
       "  'try',\n",
       "  'them',\n",
       "  'the',\n",
       "  'gumbo',\n",
       "  'was',\n",
       "  'also',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'and',\n",
       "  'tasted',\n",
       "  'much',\n",
       "  'better',\n",
       "  'than',\n",
       "  'the',\n",
       "  'gumbo',\n",
       "  'ordered',\n",
       "  'on',\n",
       "  'bourbon',\n",
       "  'street',\n",
       "  'the',\n",
       "  'fish',\n",
       "  'was',\n",
       "  'good',\n",
       "  'but',\n",
       "  'not',\n",
       "  'worth',\n",
       "  'the',\n",
       "  'price',\n",
       "  'stop',\n",
       "  'by',\n",
       "  'and',\n",
       "  'try',\n",
       "  'the',\n",
       "  'oysters',\n",
       "  'we',\n",
       "  'also',\n",
       "  'ordered',\n",
       "  'drinks',\n",
       "  'but',\n",
       "  'they',\n",
       "  'were',\n",
       "  'nothing',\n",
       "  'spectacular'],\n",
       " ['we',\n",
       "  'had',\n",
       "  'reservations',\n",
       "  'via',\n",
       "  'open',\n",
       "  'table',\n",
       "  'and',\n",
       "  'it',\n",
       "  'took',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'to',\n",
       "  'get',\n",
       "  'seated',\n",
       "  'but',\n",
       "  'it',\n",
       "  'wasn',\n",
       "  'too',\n",
       "  'long',\n",
       "  'of',\n",
       "  'wait',\n",
       "  'this',\n",
       "  'place',\n",
       "  'was',\n",
       "  'delicious',\n",
       "  'the',\n",
       "  'fried',\n",
       "  'shrimp',\n",
       "  'were',\n",
       "  'huge',\n",
       "  'and',\n",
       "  'juicy',\n",
       "  'and',\n",
       "  'most',\n",
       "  'importantly',\n",
       "  'the',\n",
       "  'breading',\n",
       "  'was',\n",
       "  'so',\n",
       "  'light',\n",
       "  'yet',\n",
       "  'the',\n",
       "  'shrimp',\n",
       "  'were',\n",
       "  'crispy',\n",
       "  'some',\n",
       "  'places',\n",
       "  'the',\n",
       "  'breading',\n",
       "  'is',\n",
       "  'super',\n",
       "  'thick',\n",
       "  'and',\n",
       "  'takes',\n",
       "  'away',\n",
       "  'from',\n",
       "  'the',\n",
       "  'taste',\n",
       "  'my',\n",
       "  'first',\n",
       "  'time',\n",
       "  'trying',\n",
       "  'grilled',\n",
       "  'oysters',\n",
       "  'and',\n",
       "  'loved',\n",
       "  'them',\n",
       "  'my',\n",
       "  'friends',\n",
       "  'had',\n",
       "  'the',\n",
       "  'raw',\n",
       "  'oysters',\n",
       "  'and',\n",
       "  'enjoyed',\n",
       "  'those',\n",
       "  'as',\n",
       "  'well',\n",
       "  'our',\n",
       "  'server',\n",
       "  'was',\n",
       "  'great',\n",
       "  'very',\n",
       "  'pleasant',\n",
       "  'with',\n",
       "  'conversation',\n",
       "  'and',\n",
       "  'his',\n",
       "  'service',\n",
       "  'was',\n",
       "  'excellent',\n",
       "  'and',\n",
       "  'he',\n",
       "  'was',\n",
       "  'properly',\n",
       "  'masked',\n",
       "  'only',\n",
       "  'improvement',\n",
       "  'would',\n",
       "  'to',\n",
       "  'have',\n",
       "  'bigger',\n",
       "  'table',\n",
       "  'to',\n",
       "  'fit',\n",
       "  'all',\n",
       "  'of',\n",
       "  'our',\n",
       "  'food',\n",
       "  'we',\n",
       "  'will',\n",
       "  'definitely',\n",
       "  'return',\n",
       "  'here',\n",
       "  'next',\n",
       "  'time',\n",
       "  'we',\n",
       "  're',\n",
       "  'in',\n",
       "  'nola'],\n",
       " ['we',\n",
       "  'came',\n",
       "  'here',\n",
       "  'for',\n",
       "  'my',\n",
       "  'moms',\n",
       "  'th',\n",
       "  'bday',\n",
       "  'first',\n",
       "  'our',\n",
       "  'waitress',\n",
       "  'brittney',\n",
       "  'was',\n",
       "  'great',\n",
       "  'we',\n",
       "  'orders',\n",
       "  'the',\n",
       "  'alligator',\n",
       "  'bites',\n",
       "  'for',\n",
       "  'appetizer',\n",
       "  'since',\n",
       "  'neither',\n",
       "  'had',\n",
       "  'them',\n",
       "  'to',\n",
       "  'chicken',\n",
       "  'to',\n",
       "  'try',\n",
       "  'the',\n",
       "  'charbroiled',\n",
       "  'oysters',\n",
       "  'which',\n",
       "  'by',\n",
       "  'the',\n",
       "  'way',\n",
       "  'we',\n",
       "  'tried',\n",
       "  'elsewhere',\n",
       "  'it',\n",
       "  'wasn',\n",
       "  'even',\n",
       "  'suggested',\n",
       "  'to',\n",
       "  'try',\n",
       "  'even',\n",
       "  'thought',\n",
       "  'that',\n",
       "  'is',\n",
       "  'one',\n",
       "  'of',\n",
       "  'all',\n",
       "  'popular',\n",
       "  'menu',\n",
       "  'item',\n",
       "  'alligator',\n",
       "  'bites',\n",
       "  'were',\n",
       "  'great',\n",
       "  'as',\n",
       "  'long',\n",
       "  'as',\n",
       "  'they',\n",
       "  'were',\n",
       "  'hot',\n",
       "  'we',\n",
       "  'ordered',\n",
       "  'the',\n",
       "  'fried',\n",
       "  'catfish',\n",
       "  'and',\n",
       "  'shrimp',\n",
       "  'combo',\n",
       "  'with',\n",
       "  'fries',\n",
       "  'an',\n",
       "  'onion',\n",
       "  'rings',\n",
       "  'and',\n",
       "  'the',\n",
       "  'sirloin',\n",
       "  'medium',\n",
       "  'with',\n",
       "  'lobster',\n",
       "  'and',\n",
       "  'mashed',\n",
       "  'potatoes',\n",
       "  'and',\n",
       "  'side',\n",
       "  'cesar',\n",
       "  'salad',\n",
       "  'the',\n",
       "  'fried',\n",
       "  'platter',\n",
       "  'was',\n",
       "  'ok',\n",
       "  'fries',\n",
       "  'seemed',\n",
       "  'dbl',\n",
       "  'fried',\n",
       "  'and',\n",
       "  'the',\n",
       "  'onions',\n",
       "  'rings',\n",
       "  'were',\n",
       "  'to',\n",
       "  'hard',\n",
       "  'the',\n",
       "  'sirloin',\n",
       "  'was',\n",
       "  'cooked',\n",
       "  'well',\n",
       "  'done',\n",
       "  'and',\n",
       "  'the',\n",
       "  'lobster',\n",
       "  'was',\n",
       "  'to',\n",
       "  'tough',\n",
       "  'to',\n",
       "  'eat',\n",
       "  'we',\n",
       "  'asked',\n",
       "  'for',\n",
       "  'that',\n",
       "  'plate',\n",
       "  'to',\n",
       "  'be',\n",
       "  'replace',\n",
       "  'with',\n",
       "  'the',\n",
       "  'fried',\n",
       "  'platter',\n",
       "  'which',\n",
       "  'actually',\n",
       "  'came',\n",
       "  'out',\n",
       "  'piping',\n",
       "  'hot',\n",
       "  'better',\n",
       "  'than',\n",
       "  'mine',\n",
       "  'dessert',\n",
       "  'was',\n",
       "  'brownie',\n",
       "  'with',\n",
       "  'ice',\n",
       "  'cream',\n",
       "  'and',\n",
       "  'load',\n",
       "  'of',\n",
       "  'whipped',\n",
       "  'cream',\n",
       "  'which',\n",
       "  'was',\n",
       "  'almost',\n",
       "  'the',\n",
       "  'best',\n",
       "  'thing',\n",
       "  'about',\n",
       "  'this',\n",
       "  'birthday',\n",
       "  'dinner',\n",
       "  'besides',\n",
       "  'the',\n",
       "  'cesar',\n",
       "  'salad',\n",
       "  'for',\n",
       "  'the',\n",
       "  'price',\n",
       "  'it',\n",
       "  'def',\n",
       "  'could',\n",
       "  'of',\n",
       "  'been',\n",
       "  'better',\n",
       "  'may',\n",
       "  'come',\n",
       "  'back',\n",
       "  'and',\n",
       "  'try',\n",
       "  'the',\n",
       "  'oysters',\n",
       "  'only'],\n",
       " ['was',\n",
       "  'hesitant',\n",
       "  'because',\n",
       "  'am',\n",
       "  'not',\n",
       "  'one',\n",
       "  'for',\n",
       "  'oysters',\n",
       "  'and',\n",
       "  'work',\n",
       "  'at',\n",
       "  'an',\n",
       "  'oyster',\n",
       "  'bar',\n",
       "  'back',\n",
       "  'home',\n",
       "  'but',\n",
       "  'holy',\n",
       "  'crap',\n",
       "  'so',\n",
       "  'yummy',\n",
       "  'we',\n",
       "  'were',\n",
       "  'all',\n",
       "  'very',\n",
       "  'impressed',\n",
       "  'with',\n",
       "  'our',\n",
       "  'food',\n",
       "  'the',\n",
       "  'only',\n",
       "  'complaint',\n",
       "  'is',\n",
       "  'we',\n",
       "  'had',\n",
       "  'girl',\n",
       "  'in',\n",
       "  'our',\n",
       "  'party',\n",
       "  'who',\n",
       "  'doesn',\n",
       "  'eat',\n",
       "  'seafood',\n",
       "  'and',\n",
       "  'online',\n",
       "  'showed',\n",
       "  'much',\n",
       "  'larger',\n",
       "  'menu',\n",
       "  'and',\n",
       "  'we',\n",
       "  'were',\n",
       "  'told',\n",
       "  'we',\n",
       "  'weren',\n",
       "  'allowed',\n",
       "  'to',\n",
       "  'order',\n",
       "  'certain',\n",
       "  'things',\n",
       "  'so',\n",
       "  'she',\n",
       "  'couldn',\n",
       "  'even',\n",
       "  'get',\n",
       "  'chicken',\n",
       "  'tenders',\n",
       "  'so',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'everyone',\n",
       "  'loves',\n",
       "  'seafood',\n",
       "  'or',\n",
       "  'doesn',\n",
       "  'have',\n",
       "  'an',\n",
       "  'allergy'],\n",
       " ['upon',\n",
       "  'booking',\n",
       "  'our',\n",
       "  'stay',\n",
       "  'at',\n",
       "  'the',\n",
       "  'hilton',\n",
       "  'riverside',\n",
       "  'my',\n",
       "  'fiance',\n",
       "  'and',\n",
       "  'learned',\n",
       "  'this',\n",
       "  'restaurant',\n",
       "  'was',\n",
       "  'on',\n",
       "  'property',\n",
       "  'upon',\n",
       "  'looking',\n",
       "  'at',\n",
       "  'some',\n",
       "  'of',\n",
       "  'the',\n",
       "  'reviews',\n",
       "  'we',\n",
       "  'decided',\n",
       "  'against',\n",
       "  'planning',\n",
       "  'to',\n",
       "  'come',\n",
       "  'here',\n",
       "  'for',\n",
       "  'meal',\n",
       "  'wellll',\n",
       "  'the',\n",
       "  'reviews',\n",
       "  'are',\n",
       "  'wrong',\n",
       "  'on',\n",
       "  'this',\n",
       "  'rainy',\n",
       "  'saturday',\n",
       "  'afternoon',\n",
       "  'our',\n",
       "  'last',\n",
       "  'full',\n",
       "  'day',\n",
       "  'in',\n",
       "  'nola',\n",
       "  'we',\n",
       "  'decided',\n",
       "  'not',\n",
       "  'to',\n",
       "  'leave',\n",
       "  'the',\n",
       "  'hotel',\n",
       "  'for',\n",
       "  'lunch',\n",
       "  'and',\n",
       "  'instead',\n",
       "  'dine',\n",
       "  'at',\n",
       "  'drago',\n",
       "  'this',\n",
       "  'was',\n",
       "  'the',\n",
       "  'best',\n",
       "  'decision',\n",
       "  'the',\n",
       "  'service',\n",
       "  'here',\n",
       "  'was',\n",
       "  'incredible',\n",
       "  'our',\n",
       "  'server',\n",
       "  'ashanti',\n",
       "  'was',\n",
       "  'such',\n",
       "  'sweetheart',\n",
       "  'making',\n",
       "  'sure',\n",
       "  'our',\n",
       "  'drinks',\n",
       "  'were',\n",
       "  'never',\n",
       "  'empty',\n",
       "  'checking',\n",
       "  'on',\n",
       "  'us',\n",
       "  'about',\n",
       "  'our',\n",
       "  'food',\n",
       "  'and',\n",
       "  'just',\n",
       "  'being',\n",
       "  'little',\n",
       "  'sunshine',\n",
       "  'on',\n",
       "  'this',\n",
       "  'cloudy',\n",
       "  'day',\n",
       "  'to',\n",
       "  'start',\n",
       "  'we',\n",
       "  'had',\n",
       "  'the',\n",
       "  'chargrilled',\n",
       "  'oysters',\n",
       "  'cuz',\n",
       "  'after',\n",
       "  'all',\n",
       "  'its',\n",
       "  'what',\n",
       "  'they',\n",
       "  're',\n",
       "  'famous',\n",
       "  'for',\n",
       "  'they',\n",
       "  'were',\n",
       "  'outrageous',\n",
       "  'the',\n",
       "  'flavors',\n",
       "  'on',\n",
       "  'them',\n",
       "  'and',\n",
       "  'the',\n",
       "  'size',\n",
       "  'of',\n",
       "  'them',\n",
       "  'makes',\n",
       "  'them',\n",
       "  'definite',\n",
       "  'must',\n",
       "  'have',\n",
       "  'when',\n",
       "  'coming',\n",
       "  'here',\n",
       "  'for',\n",
       "  'our',\n",
       "  'meals',\n",
       "  'had',\n",
       "  'the',\n",
       "  'seafood',\n",
       "  'gumbo',\n",
       "  'bowl',\n",
       "  'the',\n",
       "  'flavors',\n",
       "  'in',\n",
       "  'this',\n",
       "  'dish',\n",
       "  'are',\n",
       "  'just',\n",
       "  'perfect',\n",
       "  'definitely',\n",
       "  'recommend',\n",
       "  'dipping',\n",
       "  'some',\n",
       "  'bread',\n",
       "  'in',\n",
       "  'there',\n",
       "  'my',\n",
       "  'fiance',\n",
       "  'had',\n",
       "  'the',\n",
       "  'seafood',\n",
       "  'pasta',\n",
       "  'which',\n",
       "  'was',\n",
       "  'sooo',\n",
       "  'deliciously',\n",
       "  'creamy',\n",
       "  'overall',\n",
       "  'would',\n",
       "  'definitely',\n",
       "  'check',\n",
       "  'this',\n",
       "  'place',\n",
       "  'out',\n",
       "  'if',\n",
       "  'you',\n",
       "  're',\n",
       "  'in',\n",
       "  'nola',\n",
       "  'they',\n",
       "  'are',\n",
       "  'great',\n",
       "  'place',\n",
       "  'with',\n",
       "  'great',\n",
       "  'staff',\n",
       "  'and',\n",
       "  'great',\n",
       "  'food']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "  for sentence in sentences:\n",
    "    yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))            #deacc=True removes punctuations\n",
    "test_text = list(sent_to_words(test_text))\n",
    "test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phrases: Creating Bigram and Trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'vacationed', 'in', 'nola', 'for', 'week', 'came', 'here', 'for', 'dinner', 'had', 'reservations', 'and', 'waited', 'minutes', 'which', 'wasn', 'horrible', 'given', 'dinner', 'rush', 'hours', 'after', 'having', 'chargrilled', 'oysters', 'at', 'other', 'nearby', 'restaurants', 'feel', 'they', 'are', 'all', 'the', 'same', 'as', 'other', 'places', 'here', 'all', 'good', 'and', 'tasty', 'but', 'the', 'star', 'were', 'the', 'fried', 'shrimp', 'and', 'fish', 'platter', 'the', 'shrimp', 'was', 'so', 'good', 'lightly', 'breaded', 'huge', 'and', 'juicy', 'and', 'lots', 'of', 'flavor', 'the', 'raw', 'oysters', 'were', 'really', 'fresh', 'and', 'sweet', 'our', 'waiter', 'was', 'very', 'attentive', 'and', 'kind', 'would', 'definitely', 'come_back', 'for', 'the', 'fried', 'shrimp']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(test_text, min_count=1, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[test_text], threshold=100)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "# See examples\n",
    "print(bigram_mod[test_text[1]])\n",
    "# print(trigram_mod[bigram_mod[test_text[2]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Stopwords, make bigrams and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call  \n",
    "if find fell to download spacy en  \n",
    "download at:  \n",
    "https://github.com/explosion/spacy-models/releases/tag/en_core_web_sm-3.3.0  \n",
    "and install it with:  \n",
    "pip install en_core_web_sm-3.3.0.tar.gz  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['food',\n",
       "  'excellent',\n",
       "  'service',\n",
       "  'eat',\n",
       "  'small',\n",
       "  'plate',\n",
       "  'hit',\n",
       "  'mark',\n",
       "  'charbroile',\n",
       "  'oyster',\n",
       "  'melt',\n",
       "  'mouth',\n",
       "  'follow',\n",
       "  'cheese',\n",
       "  'gator'],\n",
       " ['vacation',\n",
       "  'week',\n",
       "  'come',\n",
       "  'dinner',\n",
       "  'reservation',\n",
       "  'wait',\n",
       "  'minute',\n",
       "  'horrible',\n",
       "  'give',\n",
       "  'dinner',\n",
       "  'rush',\n",
       "  'hour',\n",
       "  'chargrille',\n",
       "  'oyster',\n",
       "  'nearby',\n",
       "  'restaurant',\n",
       "  'feel',\n",
       "  'place',\n",
       "  'good',\n",
       "  'tasty',\n",
       "  'star',\n",
       "  'fry',\n",
       "  'fish',\n",
       "  'good',\n",
       "  'lightly',\n",
       "  'bread',\n",
       "  'huge',\n",
       "  'juicy',\n",
       "  'lot',\n",
       "  'flavor',\n",
       "  'raw',\n",
       "  'oyster',\n",
       "  'really',\n",
       "  'fresh',\n",
       "  'sweet',\n",
       "  'waiter',\n",
       "  'attentive',\n",
       "  'kind',\n",
       "  'definitely',\n",
       "  'come_back',\n",
       "  'fry',\n",
       "  'shrimp'],\n",
       " ['hype',\n",
       "  'place',\n",
       "  'reason',\n",
       "  'many',\n",
       "  'time',\n",
       "  'visit',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'try',\n",
       "  'good',\n",
       "  'oyster',\n",
       "  'city',\n",
       "  'honestly',\n",
       "  'feel',\n",
       "  'big',\n",
       "  'seafood',\n",
       "  'blow',\n",
       "  'charbroil',\n",
       "  'butter',\n",
       "  'bread',\n",
       "  'clean',\n",
       "  'friend',\n",
       "  'get',\n",
       "  'cheese',\n",
       "  'let',\n",
       "  'try',\n",
       "  'also',\n",
       "  'world',\n",
       "  'wait',\n",
       "  'go',\n",
       "  'back',\n",
       "  'someday',\n",
       "  'try',\n",
       "  'charbroile',\n",
       "  'oyster',\n",
       "  'disappoint',\n",
       "  'also',\n",
       "  'bread',\n",
       "  'pudding',\n",
       "  'die',\n",
       "  'super',\n",
       "  'moist',\n",
       "  'dry'],\n",
       " ['quick',\n",
       "  'seating',\n",
       "  'service',\n",
       "  'chargrille',\n",
       "  'oyster',\n",
       "  'fantastic',\n",
       "  'main',\n",
       "  'entree',\n",
       "  'seafood',\n",
       "  'pasta',\n",
       "  'good',\n",
       "  'plenty',\n",
       "  'seafood',\n",
       "  'daughter',\n",
       "  'shrimp',\n",
       "  'grit',\n",
       "  'crazy',\n",
       "  'decent',\n",
       "  'husband',\n",
       "  'catfish',\n",
       "  'really',\n",
       "  'good',\n",
       "  'return',\n",
       "  'especially',\n",
       "  'oyster',\n",
       "  'get',\n",
       "  'vaccine',\n",
       "  'card',\n",
       "  'hand',\n",
       "  'seat'],\n",
       " ['raw',\n",
       "  'oyster',\n",
       "  'excellent',\n",
       "  'charbroile',\n",
       "  'oyster',\n",
       "  'bread',\n",
       "  'main',\n",
       "  'dish',\n",
       "  'disguise',\n",
       "  'much',\n",
       "  'hot',\n",
       "  'sauce',\n",
       "  'drink',\n",
       "  'weak',\n",
       "  'waiter',\n",
       "  'excellent',\n",
       "  'make',\n",
       "  'miss',\n",
       "  'menu',\n",
       "  'go'],\n",
       " ['tell',\n",
       "  'drago',\n",
       "  'friend',\n",
       "  'recently',\n",
       "  'visit',\n",
       "  'locate',\n",
       "  'go',\n",
       "  'night',\n",
       "  'little',\n",
       "  'worried',\n",
       "  'take',\n",
       "  'reservation',\n",
       "  'however',\n",
       "  'wait',\n",
       "  'time',\n",
       "  'seat',\n",
       "  'right',\n",
       "  'away',\n",
       "  'order',\n",
       "  'gumbo',\n",
       "  'charbroile',\n",
       "  'oyster',\n",
       "  'bake',\n",
       "  'market',\n",
       "  'fish',\n",
       "  'highlight',\n",
       "  'oyster',\n",
       "  'pretty',\n",
       "  'cheap',\n",
       "  'absolutely',\n",
       "  'delicious',\n",
       "  'flavorful',\n",
       "  'try',\n",
       "  'gumbo',\n",
       "  'also',\n",
       "  'pretty',\n",
       "  'good',\n",
       "  'taste',\n",
       "  'much',\n",
       "  'well',\n",
       "  'gumbo',\n",
       "  'order',\n",
       "  'bourbon',\n",
       "  'street',\n",
       "  'fish',\n",
       "  'good',\n",
       "  'worth',\n",
       "  'price',\n",
       "  'stop',\n",
       "  'try',\n",
       "  'oyster',\n",
       "  'also',\n",
       "  'order',\n",
       "  'drink',\n",
       "  'spectacular'],\n",
       " ['reservation',\n",
       "  'open',\n",
       "  'table',\n",
       "  'take',\n",
       "  'little',\n",
       "  'bit',\n",
       "  'get',\n",
       "  'seat',\n",
       "  'long',\n",
       "  'wait',\n",
       "  'place',\n",
       "  'fry',\n",
       "  'shrimp',\n",
       "  'huge',\n",
       "  'juicy',\n",
       "  'importantly',\n",
       "  'bread',\n",
       "  'light',\n",
       "  'yet',\n",
       "  'place',\n",
       "  'bread',\n",
       "  'super',\n",
       "  'thick',\n",
       "  'take',\n",
       "  'taste',\n",
       "  'first',\n",
       "  'time',\n",
       "  'try',\n",
       "  'grill',\n",
       "  'oyster',\n",
       "  'love',\n",
       "  'friend',\n",
       "  'raw',\n",
       "  'oyster',\n",
       "  'enjoy',\n",
       "  'well',\n",
       "  'server',\n",
       "  'pleasant',\n",
       "  'conversation',\n",
       "  'service',\n",
       "  'excellent',\n",
       "  'properly',\n",
       "  'mask',\n",
       "  'improvement',\n",
       "  'big',\n",
       "  'table',\n",
       "  'fit',\n",
       "  'food',\n",
       "  'definitely',\n",
       "  'return',\n",
       "  'next',\n",
       "  'time'],\n",
       " ['come',\n",
       "  'mom',\n",
       "  'th',\n",
       "  'first',\n",
       "  'waitress',\n",
       "  'brittney',\n",
       "  'order',\n",
       "  'alligator_bite',\n",
       "  'appetizer',\n",
       "  'chicken',\n",
       "  'try',\n",
       "  'charbroile',\n",
       "  'oyster',\n",
       "  'way',\n",
       "  'try',\n",
       "  'elsewhere',\n",
       "  'even',\n",
       "  'suggest',\n",
       "  'try',\n",
       "  'even',\n",
       "  'think',\n",
       "  'popular',\n",
       "  'menu',\n",
       "  'item',\n",
       "  'alligator_bite',\n",
       "  'long',\n",
       "  'hot',\n",
       "  'order',\n",
       "  'fry',\n",
       "  'catfish',\n",
       "  'shrimp',\n",
       "  'combo',\n",
       "  'fry',\n",
       "  'onion',\n",
       "  'ring',\n",
       "  'sirloin',\n",
       "  'medium',\n",
       "  'lobster',\n",
       "  'mash',\n",
       "  'potato',\n",
       "  'side',\n",
       "  'fry',\n",
       "  'fry',\n",
       "  'seem',\n",
       "  'dbl',\n",
       "  'fry',\n",
       "  'onion',\n",
       "  'ring',\n",
       "  'hard',\n",
       "  'sirloin',\n",
       "  'cook',\n",
       "  'well',\n",
       "  'do',\n",
       "  'lobster',\n",
       "  'tough',\n",
       "  'ask',\n",
       "  'plate',\n",
       "  'replace',\n",
       "  'fry',\n",
       "  'actually',\n",
       "  'come',\n",
       "  'pipe',\n",
       "  'hot',\n",
       "  'well',\n",
       "  'mine',\n",
       "  'dessert',\n",
       "  'ice',\n",
       "  'cream',\n",
       "  'load',\n",
       "  'whip',\n",
       "  'cream',\n",
       "  'almost',\n",
       "  'good',\n",
       "  'thing',\n",
       "  'birthday',\n",
       "  'dinner',\n",
       "  'cesar_salad',\n",
       "  'price',\n",
       "  'def',\n",
       "  'well',\n",
       "  'come_back',\n",
       "  'try',\n",
       "  'oyster'],\n",
       " ['hesitant',\n",
       "  'oyster',\n",
       "  'work',\n",
       "  'oyster',\n",
       "  'bar',\n",
       "  'back',\n",
       "  'home',\n",
       "  'crap',\n",
       "  'impress',\n",
       "  'food',\n",
       "  'complaint',\n",
       "  'girl',\n",
       "  'eat',\n",
       "  'seafood',\n",
       "  'online',\n",
       "  'show',\n",
       "  'much',\n",
       "  'large',\n",
       "  'menu',\n",
       "  'tell',\n",
       "  'allow',\n",
       "  'order',\n",
       "  'certain',\n",
       "  'thing',\n",
       "  'even',\n",
       "  'get',\n",
       "  'chicken',\n",
       "  'tender',\n",
       "  'make_sure',\n",
       "  'love',\n",
       "  'seafood',\n",
       "  'allergy'],\n",
       " ['book',\n",
       "  'stay',\n",
       "  'riverside',\n",
       "  'fiance',\n",
       "  'learn',\n",
       "  'restaurant',\n",
       "  'property',\n",
       "  'look',\n",
       "  'review',\n",
       "  'decide',\n",
       "  'plan',\n",
       "  'come',\n",
       "  'meal',\n",
       "  'wellll',\n",
       "  'review',\n",
       "  'wrong',\n",
       "  'rainy',\n",
       "  'last',\n",
       "  'full',\n",
       "  'day',\n",
       "  'decide',\n",
       "  'leave',\n",
       "  'hotel',\n",
       "  'lunch',\n",
       "  'instead',\n",
       "  'drago',\n",
       "  'good',\n",
       "  'decision',\n",
       "  'service',\n",
       "  'incredible',\n",
       "  'server',\n",
       "  'ashanti',\n",
       "  'sweetheart',\n",
       "  'make',\n",
       "  'sure',\n",
       "  'drink',\n",
       "  'never',\n",
       "  'empty',\n",
       "  'check',\n",
       "  'food',\n",
       "  'little',\n",
       "  'sunshine',\n",
       "  'cloudy',\n",
       "  'day',\n",
       "  'start',\n",
       "  'chargrille',\n",
       "  'oyster',\n",
       "  'famous',\n",
       "  'outrageous',\n",
       "  'flavor',\n",
       "  'size',\n",
       "  'make',\n",
       "  'definite',\n",
       "  'come',\n",
       "  'meal',\n",
       "  'gumbo',\n",
       "  'bowl',\n",
       "  'flavor',\n",
       "  'dish',\n",
       "  'perfect',\n",
       "  'definitely',\n",
       "  'recommend',\n",
       "  'dip',\n",
       "  'bread',\n",
       "  'fiance',\n",
       "  'seafood',\n",
       "  'pasta',\n",
       "  'sooo',\n",
       "  'deliciously',\n",
       "  'creamy',\n",
       "  'definitely',\n",
       "  'check',\n",
       "  'place',\n",
       "  'place',\n",
       "  'staff',\n",
       "  'food']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(test_text)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "data_lemmatized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Dictionary and Corpus needed for Topic Modeling  \n",
    "Make sure to check if dictionary [id2word] or corpus is clean otherwise you may not get good quality topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('charbroile', 1),\n",
       "  ('cheese', 1),\n",
       "  ('eat', 1),\n",
       "  ('excellent', 1),\n",
       "  ('follow', 1),\n",
       "  ('food', 1),\n",
       "  ('gator', 1),\n",
       "  ('hit', 1),\n",
       "  ('mark', 1),\n",
       "  ('melt', 1),\n",
       "  ('mouth', 1),\n",
       "  ('oyster', 1),\n",
       "  ('plate', 1),\n",
       "  ('service', 1),\n",
       "  ('small', 1)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dictionary \n",
    "id2word = corpora.Dictionary(data_lemmatized)  \n",
    "# Create Corpus \n",
    "texts = data_lemmatized  \n",
    "# Term Document Frequency \n",
    "corpus = [id2word.doc2bow(text) for text in texts]  \n",
    "# View \n",
    "print(corpus[:1])\n",
    "# (8,2) above indicates, word_id 8 occurs twice in the document and so on.\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic: arameters of LDA\n",
    "\n",
    "Alpha and Beta are Hyperparameters — alpha represents document-topic density and Beta represents topic-word density, chunksize is the number of documents to be used in each training chunk, update_every determines how often the model parameters should be updated and passes is the total number of training passes.  \n",
    "A measure for best number of topics really depends on kind of corpus you are using, the size of corpus, number of topics you expect to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fast view of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.013*\"oyster\" + 0.013*\"service\" + 0.013*\"plate\" + 0.013*\"charbroile\" + '\n",
      "  '0.013*\"food\" + 0.013*\"cheese\" + 0.013*\"excellent\" + 0.013*\"eat\" + '\n",
      "  '0.013*\"small\" + 0.013*\"mark\"'),\n",
      " (1,\n",
      "  '0.027*\"oyster\" + 0.027*\"fry\" + 0.019*\"seafood\" + 0.019*\"try\" + 0.014*\"good\" '\n",
      "  '+ 0.014*\"order\" + 0.014*\"even\" + 0.014*\"well\" + 0.010*\"come\" + '\n",
      "  '0.010*\"shrimp\"'),\n",
      " (2,\n",
      "  '0.033*\"oyster\" + 0.020*\"bread\" + 0.017*\"place\" + 0.017*\"good\" + 0.017*\"try\" '\n",
      "  '+ 0.012*\"definitely\" + 0.012*\"make\" + 0.012*\"gumbo\" + 0.012*\"time\" + '\n",
      "  '0.012*\"also\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the keyword of topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the top keywords and weights associated with keywords contributing to topic.  \n",
    "Topics are words with highest probability in topic and the numbers are the probabilities of words appearing in topic distribution.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic evaluation:  \n",
    "Lower the perplexity better the model.  \n",
    "Higher the topic coherence, the topic is more human interpretable  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -5.75888651833936\n",
      "\n",
      "Coherence Score:  0.47027067749327855\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maybe useful visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cpdo\\.conda\\envs\\ARTS\\lib\\site-packages\\pyLDAvis\\_prepare.py:246: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1168823136395058088052456358\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1168823136395058088052456358_data = {\"mdsDat\": {\"x\": [-0.08736373390426529, 0.08979999152980453, -0.002436257625539209], \"y\": [-0.012935040006320439, -0.011910071293673241, 0.024845111299993717], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [64.26846995071158, 32.36826526071881, 3.363264788569608]}, \"tinfo\": {\"Term\": [\"excellent\", \"charbroile\", \"food\", \"service\", \"cheese\", \"oyster\", \"fry\", \"plate\", \"eat\", \"even\", \"seafood\", \"mouth\", \"melt\", \"gator\", \"follow\", \"hit\", \"mark\", \"small\", \"bread\", \"cream\", \"ring\", \"catfish\", \"lobster\", \"alligator_bite\", \"sirloin\", \"onion\", \"thing\", \"chicken\", \"place\", \"well\", \"bread\", \"place\", \"definitely\", \"gumbo\", \"make\", \"time\", \"also\", \"wait\", \"drink\", \"take\", \"little\", \"raw\", \"go\", \"reservation\", \"friend\", \"flavor\", \"fish\", \"dish\", \"table\", \"server\", \"taste\", \"decide\", \"check\", \"meal\", \"drago\", \"day\", \"fiance\", \"review\", \"pretty\", \"juicy\", \"excellent\", \"oyster\", \"good\", \"try\", \"food\", \"charbroile\", \"come\", \"order\", \"fry\", \"well\", \"much\", \"service\", \"even\", \"thing\", \"alligator_bite\", \"catfish\", \"sirloin\", \"lobster\", \"ring\", \"cream\", \"chicken\", \"onion\", \"certain\", \"card\", \"entree\", \"grit\", \"fantastic\", \"show\", \"husband\", \"crazy\", \"hesitant\", \"make_sure\", \"seating\", \"impress\", \"tender\", \"quick\", \"way\", \"home\", \"decent\", \"work\", \"hand\", \"bar\", \"allergy\", \"fry\", \"seafood\", \"well\", \"menu\", \"hot\", \"order\", \"oyster\", \"try\", \"shrimp\", \"get\", \"good\", \"come\", \"dinner\", \"charbroile\", \"really\", \"come_back\", \"chargrille\", \"service\", \"food\", \"much\", \"small\", \"mark\", \"follow\", \"hit\", \"gator\", \"melt\", \"mouth\", \"plate\", \"eat\", \"cheese\", \"service\", \"excellent\", \"charbroile\", \"food\", \"combo\", \"hard\", \"replace\", \"cook\", \"think\", \"almost\", \"popular\", \"whip\", \"dbl\", \"actually\", \"elsewhere\", \"appetizer\", \"birthday\", \"mash\", \"def\", \"seem\", \"oyster\", \"try\", \"order\", \"well\", \"cream\", \"fry\", \"good\", \"ring\", \"lobster\", \"time\", \"even\", \"catfish\", \"get\", \"also\", \"gumbo\", \"seafood\", \"bread\"], \"Freq\": [2.0, 3.0, 3.0, 2.0, 1.0, 13.0, 6.0, 1.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 3.0, 5.617181008168626, 4.855436875560042, 3.3232764051179533, 3.3207188004231294, 3.322926738885824, 3.3189176439191317, 3.3181880106234076, 3.318030607189159, 2.556774505671431, 2.5553101442499133, 2.556352707371477, 2.5567436685420635, 2.554670877150683, 2.553598281346605, 2.5527257246599877, 2.5544013874549085, 2.5507003956329375, 1.7908723213538633, 1.7895093202358312, 1.7898139374441895, 1.7895697878242862, 1.790089996789264, 1.7903057226203591, 1.7901420176857619, 1.7890544055404267, 1.7900307358710887, 1.7901071583221293, 1.7899909157518623, 1.7882129541321277, 1.7886456124645975, 2.558787499846734, 9.457132979536784, 4.8541460065098345, 4.852333855898845, 2.5605202783682217, 2.555664905312112, 2.5534178171025688, 2.5565221775085214, 2.5612348953226887, 1.7938010441968981, 1.7915536878384037, 1.7906584725654253, 2.0729806640224546, 1.4528124966798648, 1.4518995524204692, 1.451366641466686, 1.4514902130639267, 1.4507232588554788, 1.4506366912119473, 1.450269217642448, 1.4517238511658133, 1.4511624444666555, 0.8311709237352032, 0.8306077613740079, 0.8305914877374314, 0.8303517723438771, 0.8303016684503511, 0.8308841430939566, 0.8300556056632774, 0.8300291356817919, 0.8307897424967203, 0.8308061511842227, 0.8299204196864054, 0.8308183057675579, 0.8307742791656995, 0.8301323821146778, 0.8299425680382605, 0.8307669188902355, 0.8300735674364282, 0.830783192526812, 0.8300610752257782, 0.8306444952258653, 0.830570149691132, 3.9442206342555304, 2.7024727472923624, 2.071859741337102, 1.4527207971011473, 1.4508321099017913, 2.0740532384763184, 3.958089554044638, 2.7002276606994347, 1.4559548616247784, 1.4547982854949761, 2.0825020244035057, 1.4596060984586567, 0.8360564585067659, 0.8349006926825192, 0.8336893534022458, 0.8331259884646617, 0.8330224044044611, 0.8318512427746566, 0.831747456138067, 0.8316915450547253, 0.19508162357553793, 0.19504783299254755, 0.19502936604602955, 0.19502174632569577, 0.1950130039946314, 0.1949948878639667, 0.19498249704802795, 0.19561430236719687, 0.19509224627957603, 0.19527263579134566, 0.1956872720646844, 0.19522263751593258, 0.19559683173770226, 0.19541117998813304, 0.049359267844450286, 0.04932532991880152, 0.049315517599384566, 0.04930358635221365, 0.04929364072277244, 0.04928450547795237, 0.049282467237844664, 0.04927512466203498, 0.04925165508144885, 0.04925132531454674, 0.04924964139845088, 0.04923351088551589, 0.049230307936775214, 0.04922881696939867, 0.04922467383417113, 0.049224607179159004, 0.19754805548115284, 0.052424300348718755, 0.051170368719773617, 0.0506244361051768, 0.04979945052822672, 0.050824337994707286, 0.05056640765488155, 0.04968214121503992, 0.04966012401208648, 0.05001139241784265, 0.04975130806867762, 0.049595844023285325, 0.04989151864076819, 0.04983648264970164, 0.049756310702745755, 0.04974396900102647, 0.04967628609844826], \"Total\": [2.0, 3.0, 3.0, 2.0, 1.0, 13.0, 6.0, 1.0, 1.0, 2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 3.0, 5.884916731642223, 5.118395040497752, 3.5837899531863338, 3.5813758027812046, 3.5838692830557743, 3.580205507193749, 3.580639082466889, 3.5819839501426447, 2.815809353323007, 2.814227287179305, 2.815483558394307, 2.8164039502088607, 2.8149590688920916, 2.814704422234621, 2.8139374405656157, 2.8158581278254062, 2.8134951433038555, 2.0489642231812275, 2.047478064556282, 2.047963889098436, 2.0477742846184075, 2.0483899623883337, 2.0486829977590073, 2.0485456984694057, 2.047318616754266, 2.0485089948353936, 2.048614428153127, 2.0485168566616343, 2.046946300525665, 2.048161607331313, 2.9638149076353093, 13.612770589062574, 6.9872144385682216, 7.604985816946998, 3.5876789144944214, 3.5861624297323336, 4.062504260481127, 4.6817457847046136, 6.556279867572926, 3.9162852216391766, 2.6723792173210623, 2.8181969874047663, 2.383202662250572, 1.7606005519855696, 1.7596253640029316, 1.7590980507873861, 1.759707564209875, 1.7589734438776488, 1.7589000277623774, 1.7584865607948943, 1.7604882955735284, 1.7599542538050823, 1.1371740654709968, 1.1365413137857243, 1.1365345620538703, 1.1362410901158377, 1.1363594881091608, 1.1371714882949577, 1.1361112936910485, 1.1360913811882485, 1.1371654723562088, 1.1371895307364663, 1.1360065462308953, 1.1372373372602855, 1.1371819741409985, 1.1363176397632957, 1.1360777638139823, 1.137209693527812, 1.1362697549535785, 1.1372546808018609, 1.1363539758279633, 1.1371789686286395, 1.1371359330301352, 6.556279867572926, 4.542712154296594, 3.9162852216391766, 2.5285486670770143, 2.5274422187793157, 4.6817457847046136, 13.612770589062574, 7.604985816946998, 3.2949887752442666, 3.2935821136352796, 6.9872144385682216, 4.062504260481127, 2.671414848511727, 3.5861624297323336, 1.903252143526882, 1.903383179509908, 2.671846988026979, 2.8181969874047663, 3.5876789144944214, 2.6723792173210623, 0.6598727436187003, 0.6599776907275051, 0.6600384593347917, 0.6600604414551982, 0.6600945276377687, 0.6601504940001937, 0.6601919960619291, 1.2825320087232817, 1.2842324336805861, 1.4268009382778188, 2.8181969874047663, 2.9638149076353093, 3.5861624297323336, 3.5876789144944214, 1.135529215434135, 1.1357003003302022, 1.135785210401015, 1.1357108927794015, 1.1358599025605987, 1.1357430979515715, 1.1357584395665004, 1.1358287966636693, 1.1358982005169536, 1.1359504886667215, 1.13594611779587, 1.135925887949202, 1.1359837377691078, 1.1359585341885863, 1.1359654696696588, 1.135990923717387, 13.612770589062574, 7.604985816946998, 4.6817457847046136, 3.9162852216391766, 1.7584865607948943, 6.556279867572926, 6.9872144385682216, 1.7589000277623774, 1.7589734438776488, 3.580205507193749, 2.383202662250572, 1.7590980507873861, 3.2935821136352796, 3.580639082466889, 3.5813758027812046, 4.542712154296594, 5.884916731642223], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9369, -4.0826, -4.4617, -4.4625, -4.4618, -4.4631, -4.4633, -4.4633, -4.7239, -4.7245, -4.7241, -4.724, -4.7248, -4.7252, -4.7255, -4.7249, -4.7263, -5.08, -5.0808, -5.0806, -5.0807, -5.0804, -5.0803, -5.0804, -5.081, -5.0805, -5.0804, -5.0805, -5.0815, -5.0812, -4.7232, -3.4159, -4.0829, -4.0832, -4.7225, -4.7244, -4.7253, -4.724, -4.7222, -5.0784, -5.0796, -5.0801, -4.2478, -4.6033, -4.6039, -4.6043, -4.6042, -4.6047, -4.6048, -4.6051, -4.604, -4.6044, -5.1617, -5.1624, -5.1624, -5.1627, -5.1628, -5.1621, -5.1631, -5.1631, -5.1622, -5.1622, -5.1632, -5.1621, -5.1622, -5.163, -5.1632, -5.1622, -5.163, -5.1622, -5.1631, -5.1624, -5.1624, -3.6046, -3.9826, -4.2484, -4.6034, -4.6047, -4.2473, -3.601, -3.9835, -4.6011, -4.6019, -4.2432, -4.5986, -5.1559, -5.1572, -5.1587, -5.1594, -5.1595, -5.1609, -5.161, -5.1611, -4.3469, -4.347, -4.3471, -4.3472, -4.3472, -4.3473, -4.3474, -4.3441, -4.3468, -4.3459, -4.3438, -4.3461, -4.3442, -4.3452, -5.7212, -5.7219, -5.7221, -5.7223, -5.7225, -5.7227, -5.7227, -5.7229, -5.7233, -5.7234, -5.7234, -5.7237, -5.7238, -5.7238, -5.7239, -5.7239, -4.3343, -5.6609, -5.6851, -5.6959, -5.7123, -5.6919, -5.697, -5.7146, -5.7151, -5.708, -5.7133, -5.7164, -5.7104, -5.7115, -5.7132, -5.7134, -5.7148], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3955, 0.3894, 0.3666, 0.3665, 0.3665, 0.3663, 0.366, 0.3656, 0.3456, 0.3456, 0.3455, 0.3454, 0.3451, 0.3447, 0.3447, 0.3447, 0.344, 0.3075, 0.3074, 0.3074, 0.3073, 0.3073, 0.3073, 0.3073, 0.3073, 0.3072, 0.3072, 0.3072, 0.307, 0.3066, 0.2952, 0.0779, 0.0779, -0.0072, 0.1048, 0.1033, -0.0223, -0.1629, -0.4978, -0.3387, 0.0422, -0.0114, 0.9885, 0.9358, 0.9358, 0.9357, 0.9354, 0.9353, 0.9353, 0.9353, 0.9352, 0.9351, 0.8145, 0.8144, 0.8144, 0.8144, 0.8142, 0.8142, 0.8141, 0.8141, 0.8141, 0.8141, 0.814, 0.814, 0.814, 0.814, 0.814, 0.814, 0.814, 0.814, 0.8139, 0.8139, 0.8138, 0.6198, 0.6086, 0.4913, 0.5738, 0.5729, 0.3138, -0.1073, 0.0925, 0.3113, 0.3109, -0.0825, 0.1044, -0.0337, -0.3295, 0.3025, 0.3018, -0.0375, -0.0922, -0.3337, -0.0393, 2.1736, 2.1733, 2.1731, 2.173, 2.1729, 2.1728, 2.1726, 1.5118, 1.5078, 1.4035, 0.7249, 0.6722, 0.4835, 0.4821, 0.2565, 0.2557, 0.2554, 0.2552, 0.2549, 0.2548, 0.2548, 0.2546, 0.254, 0.254, 0.2539, 0.2536, 0.2535, 0.2535, 0.2534, 0.2534, -0.8405, -1.5849, -1.124, -0.9562, -0.1719, -1.4675, -1.5363, -0.1745, -0.175, -0.8787, -0.4769, -0.1764, -0.7976, -0.8823, -0.8841, -1.1221, -1.3824]}, \"token.table\": {\"Topic\": [2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 2], \"Freq\": [0.8803200579399475, 0.8794023396440319, 0.5683027878872596, 0.8804808075026844, 0.8378392602286918, 0.8803391230086302, 0.8793690593890704, 0.8802942918565381, 1.0195556324083557, 0.8798624281145428, 0.5684731442641257, 0.8793728509679107, 0.8365488342433826, 0.27884961141446085, 0.7485458594606486, 0.3742729297303243, 0.9762369298655477, 0.7008686167581462, 0.5680242251620434, 0.8806466503969962, 0.7384607640127635, 0.24615358800425452, 0.5253802864105821, 0.5253802864105821, 0.8805057751561411, 0.8802108849325929, 0.5686708231355302, 0.9763198526549347, 0.8803605812078006, 0.8800727077707479, 0.976376586842911, 0.8803084483640177, 0.8371026313449849, 0.7486669474470506, 0.3743334737235253, 0.9761029389253046, 0.9768875169858597, 1.0654130388691354, 0.7786752411586575, 0.8803234452179363, 0.8798676550520963, 0.8392068503780977, 1.0122089582151272, 0.8800032124199927, 0.9762696056978599, 1.066289382848244, 1.0653945844625348, 0.8361952313736422, 0.27873174379121407, 1.0661217825073555, 0.45757656179960665, 0.6101020823994755, 0.6072415780132189, 0.30362078900660944, 1.065734856734786, 0.7155927507249327, 0.28623710028997307, 0.8800949100494613, 0.8376669093677008, 0.8800074811824248, 0.8805139874571244, 0.8793794960446683, 0.8793453007754753, 0.3956569185122547, 0.3956569185122547, 0.8801954575692632, 0.8793239258298505, 0.9764854456997336, 1.0655363236114666, 0.5685134152994968, 0.8370841018626829, 0.8793608918931748, 0.8803138229990928, 0.9763023600080403, 0.39548378602338446, 0.39548378602338446, 0.7483967795576962, 0.3741983897788481, 0.5681965868362574, 0.6407866078079418, 0.4271910718719612, 0.6611438825856076, 0.2938417255936034, 0.9768687177208896, 0.7797076355197302, 0.8804689141307926, 0.9770652017038215, 0.8800356212091438, 1.0651881097445286, 0.5254164580353069, 0.5254164580353069, 0.8804481611861515, 1.0658312738991866, 0.9763161057211412, 0.5685371449292497, 0.44026562372180184, 0.6603984355827027, 0.8802766175228961, 0.8802887233708048, 0.9765797193232978, 0.7096735994462079, 0.35483679972310395, 0.8793748438939243, 0.6069823408887742, 0.3034911704443871, 0.5682762410861201, 0.9768114416568506, 1.066011979084637, 0.9766701413445525, 0.8793667352627335, 0.5679880077694058, 0.8803902644557431, 0.8379407254617269, 0.6574634220695019, 0.39447805324170115, 0.8375246907179836, 0.8802214354084803, 0.5106880338922026, 0.5106880338922026, 0.8804143748929006, 0.8793105158247538], \"Term\": [\"actually\", \"allergy\", \"alligator_bite\", \"almost\", \"also\", \"appetizer\", \"bar\", \"birthday\", \"bread\", \"card\", \"catfish\", \"certain\", \"charbroile\", \"charbroile\", \"chargrille\", \"chargrille\", \"check\", \"cheese\", \"chicken\", \"combo\", \"come\", \"come\", \"come_back\", \"come_back\", \"cook\", \"crazy\", \"cream\", \"day\", \"dbl\", \"decent\", \"decide\", \"def\", \"definitely\", \"dinner\", \"dinner\", \"dish\", \"drago\", \"drink\", \"eat\", \"elsewhere\", \"entree\", \"even\", \"excellent\", \"fantastic\", \"fiance\", \"fish\", \"flavor\", \"food\", \"food\", \"friend\", \"fry\", \"fry\", \"get\", \"get\", \"go\", \"good\", \"good\", \"grit\", \"gumbo\", \"hand\", \"hard\", \"hesitant\", \"home\", \"hot\", \"hot\", \"husband\", \"impress\", \"juicy\", \"little\", \"lobster\", \"make\", \"make_sure\", \"mash\", \"meal\", \"menu\", \"menu\", \"much\", \"much\", \"onion\", \"order\", \"order\", \"oyster\", \"oyster\", \"place\", \"plate\", \"popular\", \"pretty\", \"quick\", \"raw\", \"really\", \"really\", \"replace\", \"reservation\", \"review\", \"ring\", \"seafood\", \"seafood\", \"seating\", \"seem\", \"server\", \"service\", \"service\", \"show\", \"shrimp\", \"shrimp\", \"sirloin\", \"table\", \"take\", \"taste\", \"tender\", \"thing\", \"think\", \"time\", \"try\", \"try\", \"wait\", \"way\", \"well\", \"well\", \"whip\", \"work\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1168823136395058088052456358\", ldavis_el1168823136395058088052456358_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1168823136395058088052456358\", ldavis_el1168823136395058088052456358_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1168823136395058088052456358\", ldavis_el1168823136395058088052456358_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.087364 -0.012935       1        1  64.268470\n",
       "1      0.089800 -0.011910       2        1  32.368265\n",
       "0     -0.002436  0.024845       3        1   3.363265, topic_info=           Term      Freq     Total Category  logprob  loglift\n",
       "3     excellent  2.000000  2.000000  Default  30.0000  30.0000\n",
       "0    charbroile  3.000000  3.000000  Default  29.0000  29.0000\n",
       "5          food  3.000000  3.000000  Default  28.0000  28.0000\n",
       "13      service  2.000000  2.000000  Default  27.0000  27.0000\n",
       "1        cheese  1.000000  1.000000  Default  26.0000  26.0000\n",
       "..          ...       ...       ...      ...      ...      ...\n",
       "64          get  0.049892  3.293582   Topic3  -5.7104  -0.7976\n",
       "52         also  0.049836  3.580639   Topic3  -5.7115  -0.8823\n",
       "118       gumbo  0.049756  3.581376   Topic3  -5.7132  -0.8841\n",
       "74      seafood  0.049744  4.542712   Topic3  -5.7134  -1.1221\n",
       "16        bread  0.049676  5.884917   Topic3  -5.7148  -1.3824\n",
       "\n",
       "[170 rows x 6 columns], token_table=      Topic      Freq            Term\n",
       "term                                 \n",
       "159       2  0.880320        actually\n",
       "203       2  0.879402         allergy\n",
       "160       2  0.568303  alligator_bite\n",
       "161       2  0.880481          almost\n",
       "52        1  0.837839            also\n",
       "...     ...       ...             ...\n",
       "201       2  0.880221             way\n",
       "136       1  0.510688            well\n",
       "136       2  0.510688            well\n",
       "202       2  0.880414            whip\n",
       "218       2  0.879311            work\n",
       "\n",
       "[121 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 2, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cpdo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  3217\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Cpdo\\Desktop\\ARTS-Porject\\precompute\\precompute.ipynb Cell 36'\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cpdo/Desktop/ARTS-Porject/precompute/precompute.ipynb#ch0000035?line=74'>75</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cpdo/Desktop/ARTS-Porject/precompute/precompute.ipynb#ch0000035?line=75'>76</a>\u001b[0m         test_text \u001b[39m=\u001b[39m per_month_texts[key_month]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Cpdo/Desktop/ARTS-Porject/precompute/precompute.ipynb#ch0000035?line=76'>77</a>\u001b[0m         test_text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m before \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cpdo/Desktop/ARTS-Porject/precompute/precompute.ipynb#ch0000035?line=77'>78</a>\u001b[0m         before \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m per_month_texts[key_month]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Cpdo/Desktop/ARTS-Porject/precompute/precompute.ipynb#ch0000035?line=78'>79</a>\u001b[0m \u001b[39m# Remove ()\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from pprint import pprint# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "# spaCy for preprocessing\n",
    "import spacy\n",
    "# import pyLDAvis.gensim\n",
    "import gensim\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "# NLTK Stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','great'])\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))            #deacc=True removes punctuations\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "# DcBLYSvOuWcNReolRVr12A Drago's\n",
    "business_id = 'DcBLYSvOuWcNReolRVr12A'\n",
    "df = pd.read_csv(\"./new_orlean_restaurant_reviews.csv\")\n",
    "target_bus_df = df.loc[df['business_id'] == business_id]\n",
    "print(\"number of reviews: \",len(target_bus_df.index))\n",
    "target_bus_df = target_bus_df.sort_values(by=['date'])\n",
    "start_year = int(target_bus_df.iloc[0].at['date'][0:4])\n",
    "end_year = int(target_bus_df.iloc[-1].at['date'][0:4])\n",
    "start_month = int(target_bus_df.iloc[0].at['date'][5:7])\n",
    "end_month = int(target_bus_df.iloc[-1].at['date'][5:7])\n",
    "# text - month dictionary re-scaled to 0 - (month_count-1)\n",
    "text_month_dict = {}\n",
    "for i in range(0,len(target_bus_df.index)):\n",
    "    real_year = int(target_bus_df.iloc[i].at['date'][0:4])\n",
    "    real_month = int(target_bus_df.iloc[i].at['date'][5:7])\n",
    "    key_month = (real_year - start_year) * 12 + (real_month - start_month)\n",
    "    if key_month in text_month_dict:\n",
    "        text_month_dict[key_month].append(target_bus_df.iloc[i].at['text'])\n",
    "    else:\n",
    "        text_month_dict[key_month] = [target_bus_df.iloc[i].at['text']]\n",
    "month_count = (end_year - start_year) * 12 + (end_month - start_month) + 1\n",
    "per_month_texts = []\n",
    "for key_month in range(month_count):\n",
    "    if key_month in text_month_dict:\n",
    "        per_month_texts.append(text_month_dict[key_month])\n",
    "    else:\n",
    "        per_month_texts.append(per_month_texts[key_month-1]) \n",
    "\n",
    "for key_month in range(month_count):\n",
    "    test_text = \"\"\n",
    "    if len(per_month_texts[key_month]) >= 4:\n",
    "        test_text = per_month_texts[key_month]\n",
    "        before = per_month_texts[key_month]\n",
    "    else:\n",
    "        test_text = per_month_texts[key_month]\n",
    "        test_text += before \n",
    "        before += per_month_texts[key_month]\n",
    "    # Remove ()\n",
    "    test_text = [sent.replace(\"(\",\" \") for sent in test_text]\n",
    "    test_text = [sent.replace(\")\",\" \")  for sent in test_text]    \n",
    "    # Remove new line characters \n",
    "    test_text = [sent.replace(\"\\n\",\" \") for sent in test_text]  \n",
    "    # Remove distracting single quotes \n",
    "    test_text = [sent.replace(\"\\'\",\" \") for sent in test_text]  \n",
    "    test_text = list(sent_to_words(test_text))\n",
    "    # Create Dictionary \n",
    "    id2word = corpora.Dictionary(data_lemmatized)  \n",
    "    # Create Corpus \n",
    "    texts = data_lemmatized  \n",
    "    # Term Document Frequency \n",
    "    corpus = [id2word.doc2bow(text) for text in texts]  \n",
    "    # View \n",
    "    print(corpus[:1])\n",
    "    # (8,2) above indicates, word_id 8 occurs twice in the document and so on.\n",
    "    [[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=id2word,num_topics=3, random_state=100,\n",
    "                                            update_every=1,chunksize=100,passes=10,alpha='auto',per_word_topics=True)\n",
    "\n",
    "    x=lda_model.show_topics(num_topics=3, num_words=8,formatted=False)\n",
    "    topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "    print (topics_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Cpdo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of reviews:  3217\n",
      "2008 3 2022 1 167\n",
      "the test text is the month: 166 th\n",
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1)]]\n",
      "[(0, ['oyster', 'service', 'plate', 'charbroile', 'food', 'mark', 'eat', 'follow', 'small', 'hit', 'melt', 'gator', 'mouth', 'cheese', 'excellent', 'try', 'good', 'fry', 'order', 'catfish', 'seafood', 'well', 'cream', 'ring', 'daughter', 'get', 'plenty', 'pasta', 'really', 'seating']), (1, ['oyster', 'fry', 'seafood', 'try', 'good', 'even', 'order', 'well', 'come', 'shrimp', 'get', 'thing', 'catfish', 'menu', 'chicken', 'alligator_bite', 'ring', 'onion', 'hot', 'sirloin', 'lobster', 'cream', 'chargrille', 'really', 'service', 'main', 'card', 'entree', 'dinner', 'return']), (2, ['oyster', 'make', 'place', 'bread', 'definitely', 'food', 'drink', 'excellent', 'flavor', 'dish', 'come', 'decide', 'check', 'meal', 'day', 'fiance', 'review', 'gumbo', 'good', 'little', 'raw', 'charbroile', 'much', 'go', 'drago', 'server', 'hot', 'service', 'menu', 'chargrille']), (3, ['oyster', 'try', 'bread', 'good', 'time', 'also', 'place', 'wait', 'fry', 'order', 'friend', 'take', 'reservation', 'fish', 'gumbo', 'well', 'charbroile', 'get', 'shrimp', 'big', 'dinner', 'super', 'visit', 'go', 'table', 'feel', 'seat', 'juicy', 'taste', 'definitely'])]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from pprint import pprint# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "# spaCy for preprocessing\n",
    "import spacy\n",
    "# import pyLDAvis.gensim\n",
    "import gensim\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords') \n",
    "# NLTK Stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use','great'])\n",
    "\n",
    "# DcBLYSvOuWcNReolRVr12A Drago's\n",
    "business_id = 'DcBLYSvOuWcNReolRVr12A'\n",
    "df = pd.read_csv(\"./new_orlean_restaurant_reviews.csv\")\n",
    "target_bus_df = df.loc[df['business_id'] == business_id]\n",
    "print(\"number of reviews: \",len(target_bus_df.index))\n",
    "target_bus_df = target_bus_df.sort_values(by=['date'])\n",
    "\n",
    "start_year = int(target_bus_df.iloc[0].at['date'][0:4])\n",
    "end_year = int(target_bus_df.iloc[-1].at['date'][0:4])\n",
    "start_month = int(target_bus_df.iloc[0].at['date'][5:7])\n",
    "end_month = int(target_bus_df.iloc[-1].at['date'][5:7])\n",
    "# text - month dictionary re-scaled to 0 - (month_count-1)\n",
    "text_month_dict = {}\n",
    "for i in range(0,len(target_bus_df.index)):\n",
    "    real_year = int(target_bus_df.iloc[i].at['date'][0:4])\n",
    "    real_month = int(target_bus_df.iloc[i].at['date'][5:7])\n",
    "    key_month = (real_year - start_year) * 12 + (real_month - start_month)\n",
    "    if key_month in text_month_dict:\n",
    "        text_month_dict[key_month].append(target_bus_df.iloc[i].at['text'])\n",
    "    else:\n",
    "        text_month_dict[key_month] = [target_bus_df.iloc[i].at['text']]\n",
    "        \n",
    "# ensure every month has a average star\n",
    "month_count = (end_year - start_year) * 12 + (end_month - start_month) + 1\n",
    "per_month_texts = []\n",
    "for key_month in range(month_count):\n",
    "    if key_month in text_month_dict:\n",
    "        per_month_texts.append(text_month_dict[key_month])\n",
    "    else:\n",
    "        per_month_texts.append(per_month_texts[key_month-1]) \n",
    "# print (per_month_stars, start_year, start_month, end_year, end_month)\n",
    "print (start_year, start_month, end_year, end_month, month_count)\n",
    "\n",
    "test_text = \"\"\n",
    "for key_month in range(month_count):\n",
    "    if len(per_month_texts[key_month]) >= 0:\n",
    "        test_text = per_month_texts[key_month]\n",
    "print(\"the test text is the month:\",key_month,\"th\")\n",
    "# test_text\n",
    "\n",
    "# Remove ()\n",
    "test_text = [sent.replace(\"(\",\" \") for sent in test_text]\n",
    "test_text = [sent.replace(\")\",\" \")  for sent in test_text]    \n",
    "# Remove new line characters \n",
    "test_text = [sent.replace(\"\\n\",\" \") for sent in test_text]  \n",
    "# Remove distracting single quotes \n",
    "test_text = [sent.replace(\"\\'\",\" \") for sent in test_text]  \n",
    "test_text\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "  for sentence in sentences:\n",
    "    yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))            #deacc=True removes punctuations\n",
    "test_text = list(sent_to_words(test_text))\n",
    "test_text\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# Create Dictionary \n",
    "id2word = corpora.Dictionary(data_lemmatized)  \n",
    "# Create Corpus \n",
    "texts = data_lemmatized  \n",
    "# Term Document Frequency \n",
    "corpus = [id2word.doc2bow(text) for text in texts]  \n",
    "# View \n",
    "print(corpus[:1])\n",
    "# (8,2) above indicates, word_id 8 occurs twice in the document and so on.\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "x=lda_model.show_topics(num_topics=4, num_words=30,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "print (topics_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "# Print the keyword of topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, ['oyster', 'service', 'plate', 'charbroile', 'food', 'cheese', 'excellent', 'eat', 'small', 'mark']), (1, ['oyster', 'fry', 'seafood', 'try', 'good', 'order', 'even', 'well', 'come', 'shrimp']), (2, ['oyster', 'bread', 'place', 'good', 'try', 'definitely', 'make', 'gumbo', 'time', 'also'])]\n"
     ]
    }
   ],
   "source": [
    "x=lda_model.show_topics(num_topics=3, num_words=10,formatted=False)\n",
    "topics_words = [(tp[0], [wd[0] for wd in tp[1]]) for tp in x]\n",
    "print (topics_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "# Visualize the topics\n",
    "import pyLDAvis.gensim_models\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce6e4faf1d986ba70bda5bfab75ddffea4bf50447eb2a9b922021db23a1c2ef7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ARTS')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
